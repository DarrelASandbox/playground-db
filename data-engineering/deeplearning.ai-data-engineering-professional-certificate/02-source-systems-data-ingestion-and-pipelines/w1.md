- [Introduction to Source Systems](#introduction-to-source-systems)
  - [Data Source Systems in Data Engineering](#data-source-systems-in-data-engineering)
    - [Data Types](#data-types)
      - [Structured Data](#structured-data)
      - [Semi-Structured Data](#semi-structured-data)
      - [Unstructured Data](#unstructured-data)
    - [Source Systems](#source-systems)
      - [Databases](#databases)
      - [Files](#files)
      - [Streaming Systems](#streaming-systems)
    - [Key Considerations](#key-considerations)
  - [Relational Databases](#relational-databases)
    - [Common Use Cases](#common-use-cases)
    - [Schema and Table Relationships](#schema-and-table-relationships)
    - [Benefits of Normalization](#benefits-of-normalization)
    - [Alternative Approaches](#alternative-approaches)
    - [Working with RDBMS](#working-with-rdbms)
  - [SQL Queries in Rentio's DVD Rental Database](#sql-queries-in-rentios-dvd-rental-database)
    - [Database Overview](#database-overview)
    - [Basic SQL Queries](#basic-sql-queries)
      - [Filtering and Sorting](#filtering-and-sorting)
    - [Joining Tables](#joining-tables)
    - [Aggregation](#aggregation)
    - [Data Manipulation](#data-manipulation)
  - [NoSQL Databases](#nosql-databases)
    - [Emergence and Motivation](#emergence-and-motivation)
    - [Key Characteristics](#key-characteristics)
    - [Types of NoSQL Databases](#types-of-nosql-databases)
      - [Key-Value Stores](#key-value-stores)
      - [Document Databases](#document-databases)
    - [Use Cases and Considerations](#use-cases-and-considerations)
  - [Database ACID Compliance](#database-acid-compliance)
    - [Overview](#overview)
    - [ACID Principles](#acid-principles)
      - [**Atomicity**](#atomicity)
      - [**Consistency**](#consistency)
      - [**Isolation**](#isolation)
      - [**Durability**](#durability)
    - [Strong Consistency vs. Performance](#strong-consistency-vs-performance)
  - [Lab Walkthrough - Interacting with Amazon DynamoDB NoSQL Database](#lab-walkthrough---interacting-with-amazon-dynamodb-nosql-database)
    - [DynamoDB Basics](#dynamodb-basics)
      - [Data Structure Examples](#data-structure-examples)
    - [Lab Setup and Tools](#lab-setup-and-tools)
    - [Table Structure and Data Files](#table-structure-and-data-files)
      - [Data File Attributes](#data-file-attributes)
    - [Table Creation Process](#table-creation-process)
      - [Example Table Definition](#example-table-definition)
  - [Object Storage](#object-storage)
    - [Object Storage Fundamentals](#object-storage-fundamentals)
      - [Key Components](#key-components)
    - [Benefits of Object Storage](#benefits-of-object-storage)
    - [Cloud Object Storage Use Cases](#cloud-object-storage-use-cases)
    - [Amazon S3 Features](#amazon-s3-features)
  - [Logs](#logs)
    - [Role of Logs](#role-of-logs)
      - [Log Structure](#log-structure)
    - [Log Formats \& Applications](#log-formats--applications)
    - [Importance for Data Engineers](#importance-for-data-engineers)
  - [Streaming Systems](#streaming-systems-1)
    - [Key Terminology](#key-terminology)
    - [Components of a Streaming System](#components-of-a-streaming-system)
      - [**Event Producer**](#event-producer)
      - [**Event Router (Streaming Broker)**](#event-router-streaming-broker)
      - [**Event Consumer**](#event-consumer)
    - [Types of Streaming Systems](#types-of-streaming-systems)
      - [Message Queues](#message-queues)
      - [Streaming Platforms](#streaming-platforms)
    - [Applications in Data Engineering](#applications-in-data-engineering)
- [Connecting to Source Systems](#connecting-to-source-systems)
  - [Overview](#overview-1)
    - [Challenges in Connecting to Source Systems](#challenges-in-connecting-to-source-systems)
    - [IAM and Security](#iam-and-security)
    - [Networking in AWS](#networking-in-aws)
      - [Core Networking Components](#core-networking-components)
    - [Methods of Connecting to Source Systems](#methods-of-connecting-to-source-systems)
      - [SDKs and Automation](#sdks-and-automation)
    - [Troubleshooting and Real-World Application](#troubleshooting-and-real-world-application)
  - [Connecting to an Amazon RDS MySQL Database](#connecting-to-an-amazon-rds-mysql-database)
    - [Setting up an RDS in your account](#setting-up-an-rds-in-your-account)
    - [How to connect to an RDS instance?](#how-to-connect-to-an-rds-instance)
    - [Connecting to the database through AWS CloudShell](#connecting-to-the-database-through-aws-cloudshell)
    - [Connecting to the database through Python](#connecting-to-the-database-through-python)
    - [Final Remark](#final-remark)
  - [Basics of IAM and Permissions](#basics-of-iam-and-permissions)
    - [Importance of IAM](#importance-of-iam)
    - [Core IAM Concepts](#core-iam-concepts)
      - [Common IAM Components](#common-iam-components)
    - [IAM Policies](#iam-policies)
      - [Example Policy Snippet](#example-policy-snippet)
    - [Best Practices](#best-practices)
  - [Basics of AWS IAM](#basics-of-aws-iam)
    - [What is IAM?](#what-is-iam)
    - [What is an IAM user?](#what-is-an-iam-user)
    - [What is an IAM group?](#what-is-an-iam-group)
    - [What is an IAM role?](#what-is-an-iam-role)
    - [What is an IAM Policy?](#what-is-an-iam-policy)
    - [Learn more](#learn-more)
  - [Basics of Networking in the Cloud](#basics-of-networking-in-the-cloud)
    - [Global AWS Infrastructure](#global-aws-infrastructure)
    - [Virtual Private Clouds (VPCs)](#virtual-private-clouds-vpcs)
      - [Key Considerations](#key-considerations-1)
    - [Impact on Data Pipelines](#impact-on-data-pipelines)
  - [AWS Networking Overview - VPC](#aws-networking-overview---vpc)
    - [VPC](#vpc)
    - [Internet Gateway](#internet-gateway)
    - [NAT Gateway](#nat-gateway)
    - [Route Table](#route-table)
    - [Network ACL](#network-acl)
    - [Security Groups](#security-groups)
    - [Endpoints (optional)](#endpoints-optional)
  - [Troubleshooting AWS Network Connectivity](#troubleshooting-aws-network-connectivity)
    - [VPC and Subnets](#vpc-and-subnets)
    - [Security Groups](#security-groups-1)
    - [Network ACLs](#network-acls)
    - [Troubleshooting Steps](#troubleshooting-steps)
- [Week 1 Quiz](#week-1-quiz)
  - [Questions](#questions)
  - [Answers](#answers)

# Introduction to Source Systems

## Data Source Systems in Data Engineering

### Data Types

#### Structured Data

- **Structured data**: Organized as tables with rows and columns (e.g., spreadsheets, relational databases, CSV files).

#### Semi-Structured Data

- **Semi-structured data**: Non-tabular format with partial structure (e.g., **JSON** using key-value pairs and nested objects).
- Supports multiple data types (strings, numbers, arrays) and nested hierarchies.

#### Unstructured Data

- **Unstructured data**: No predefined format (e.g., text, images, audio, video).
- May have inherent structure (e.g., pixel dimensions in images or metadata in audio files).

### Source Systems

#### Databases

- **Relational databases**: Store tabular data managed via **CRUD** operations (Create, Read, Update, Delete) using a **DBMS**.
- **NoSQL databases**: Handle non-tabular data (e.g., documents, graphs) for flexible schemas and scalability.

#### Files

- Universal medium for data exchange, including structured (CSV), semi-structured (JSON, XML), and unstructured formats (images, videos).
- Stored in file systems (**Google Drive**) or **object storage** systems like **Amazon S3**.

#### Streaming Systems

- **Streaming systems**: Deliver continuous event data as messages (e.g., **Kafka**, **Kinesis**).
- **IoT applications**: Generate real-time events (e.g., smart thermostats sending temperature readings).
- Used across the data lifecycle for ingestion, transformation, and real-time analytics.

### Key Considerations

- **Source system roles**: Databases, files, and streaming systems can serve multiple purposes in pipelines (e.g., raw data extraction or intermediate processing).
- **Streaming platforms**: Enable embedded analytics dashboards and real-time decision-making.

## Relational Databases

### Common Use Cases

- **Relational databases** are pervasive, especially for **OLTP (Online Transaction Processing)** in banking, online bookings, and corporate systems.
- Widely used in **web and mobile application backends**, **customer relationship management (CRM)**, **human resources (HR)**, and **enterprise resource planning (ERP)** systems.
- Data is stored in **related tables** to reduce redundancy and maintain consistency.

### Schema and Table Relationships

- **Database schema**: Defines how data is organized into tables and columns.
- **Primary key**: Uniquely identifies each row in a table (e.g., `id` in a **customers** table).
- **Foreign key**: References a primary key in another table (e.g., `customer_id` in an **orders** table).
- Each column has a **unique name** and a **specified data type** (e.g., string, integer).

### Benefits of Normalization

- **Data normalization**: Minimizes redundancy, ensures data integrity, and simplifies updates.
- Changing customer or product details requires updating only one row in the respective table.
- Highly normalized structures can **slow down queries** due to the need for joins.

### Alternative Approaches

- **One big table (OBT)**: Stores all data in a single table for faster queries but can introduce redundancy.
- Trade-offs between **data integrity** and **query performance** depend on project requirements.

### Working with RDBMS

- **RDBMS (Relational Database Management System)**: Software layer for interacting with relational databases.
- Popular RDBMS include **MySQL**, **PostgreSQL**, **Oracle**, and **SQL Server**.
- **SQL (Structured Query Language)**: Standard language for querying and manipulating relational data.
- **As a data engineer**: SQL is integral to daily tasks, from data ingestion to analysis.

## SQL Queries in Rentio's DVD Rental Database

### Database Overview

- **Rentio**: A fictitious DVD rental company with tables for stores, staff, customers, DVD inventory, and rental transactions.
- The database is **normalized** to reduce redundancy (e.g., addresses stored separately).
- **Entity Relationship Model**: Illustrates how tables are related via **primary** and **foreign keys**.

### Basic SQL Queries

- **SELECT**: Specifies the columns to retrieve.
- **FROM**: Identifies the table to query.
- **LIMIT**: Restricts the number of rows returned.
- **SELECT \***: Retrieves all columns from the specified table (use with caution on large datasets).

#### Filtering and Sorting

- **WHERE**: Filters results based on a specified condition (e.g., `length < 60`).
- **ORDER BY**: Sorts results in **ASC** (ascending) or **DESC** (descending) order.
- **LIMIT**: Combines with **WHERE** or **ORDER BY** to refine results further.

### Joining Tables

- **JOIN**: Combines rows from multiple tables based on matching column values.
- **INNER JOIN**: Returns only matching records from both tables.
- **LEFT JOIN**: Returns all records from the first (left) table, plus matching records from the second.
- **RIGHT JOIN**: Returns all records from the second (right) table, plus matching records from the first.
- **FULL JOIN**: Returns all records from both tables, matching where possible.

### Aggregation

- **GROUP BY**: Groups rows based on a specified column (e.g., `category.name`).
- **COUNT**: Tallies the number of rows in each group.
- **AS**: Provides an alias for aggregated columns (e.g., `film_count`).

### Data Manipulation

- **CREATE**: Creates new database objects (e.g., tables).
- **INSERT INTO**: Adds new rows to a table.
- **UPDATE**: Modifies existing rows.
- **DELETE**: Removes rows from a table.

## NoSQL Databases

### Emergence and Motivation

- **Early 2000s**: Tech giants like Google and Amazon outgrew **relational databases**.
- **NoSQL** (Not Only SQL) was developed to address performance and **scalability** issues.
- Trades **RDBMS** features like **strong consistency** and fixed schemas for **flexibility** and **horizontal scaling**.

### Key Characteristics

- **Flexible schema**: No predefined structure is required, enabling rapid changes.
- **Horizontal scaling**: Distributes data and workloads across multiple servers.
- **Eventual consistency**: Updates propagate over time, allowing for faster writes.
- May **not guarantee** full **ACID compliance** (some, like **MongoDB**, do).

### Types of NoSQL Databases

#### Key-Value Stores

- Store data as **key-value pairs** (e.g., JSON or Python dictionary format).
- Ideal for **fast lookups** such as caching user session data.
- **Key**: Unique identifier, **Value**: Data (complex or simple structures).

#### Document Databases

- Specialized form of key-value stores using **JSON-like documents**.
- Organized into **collections** (similar to tables in RDBMS).
- **No joins**: Can complicate data retrieval across multiple documents.
- **Flexible schema**: Each document can vary in structure.

### Use Cases and Considerations

- Suitable for **social media** or **content distribution** where **speed** and **availability** are critical.
- Relational databases remain key for **OLTP (Online Transaction Processing)** in banking and finance, where **data consistency** is paramount.
- **Before deployment**: Ensure data integrity if sourcing from NoSQL, as schemas can change easily.

## Database ACID Compliance

### Overview

- Both **relational** and **NoSQL** databases can support high **OLTP (Online Transaction Processing)** workloads.
- **Relational databases** are generally **ACID compliant** by default.
- **NoSQL** solutions often require extra configuration for full ACID compliance.

### ACID Principles

#### **Atomicity**

- Ensures all operations in a transaction succeed or none do.
- Partial updates are rolled back to prevent inconsistent states.

#### **Consistency**

- **Before ingestion**: Data changes must respect database rules and constraints.
- Guarantees moving from one valid state to another.
- Different from **strong consistency** (which refers to up-to-date reads on all nodes).

#### **Isolation**

- Concurrent transactions behave as if they’re executed sequentially.
- Prevents conflicts and race conditions in shared data scenarios.

#### **Durability**

- Once a transaction is committed, its changes persist even after system failures.
- Critical for maintaining long-term data reliability.

### Strong Consistency vs. Performance

- **Strong consistency**: All nodes see updated data immediately, vital for banking and financial transactions.
- Relaxing ACID principles can boost **performance** and **scalability**.
- Deciding on the level of ACID compliance is key to avoiding data inconsistencies.

## Lab Walkthrough - Interacting with Amazon DynamoDB NoSQL Database

### DynamoDB Basics

- **Amazon DynamoDB**: Key-value NoSQL database storing items in schemaless tables.
- **Primary key**: Uniquely identifies each item (row) in a table.
  - **Simple primary key**: Single attribute (e.g., `Person ID`).
  - **Composite primary key**: Combines **partition key** (determines storage partition) and **sort key** (sorts items within a partition).
- **Schemaless design**: Items can have varying attributes without predefined schema.

#### Data Structure Examples

- **Person table**: Simple key (`Person ID`) with attributes like name and age.
- **Order table**: Composite key (`Order ID` as partition key, `Line Number` as sort key).

### Lab Setup and Tools

- **Python and Boto3 SDK**: Used to interact with DynamoDB via Jupyter Notebook.
- **Key Boto3 methods**:
  - **CRUD operations**: `createTable`, `putItem`, `getItem`, `updateItem`, `deleteItem`, `scan`, `query`.
  - **Batch operations**: `batchWriteItems` for bulk data insertion.
- **Client object**: Created to interface with DynamoDB (e.g., `dynamodb = boto3.client('dynamodb')`).

### Table Structure and Data Files

- **Four tables created** from JSON files:
  1. **Product Catalog**: Simple key (`Product ID`).
  2. **Forum**: Simple key (`Forum Name`), tracking threads/messages/views.
  3. **Thread**: Composite key (`Forum Name` as partition key, `Thread Subject` as sort key).
  4. **Reply**: Composite key (`Reply ID` as partition key, `Reply Time` as sort key).

#### Data File Attributes

- **DynamoDB data types**: Defined using descriptors like **`N` (number)** and **`S` (string)**.
- **Example**: Forum file includes `PutRequest` elements with attributes (e.g., `Messages: { "N": "3" }`).

### Table Creation Process

- **`createTable` method**: Defines table name, attribute types, and key schema.
  - **Key schema arguments**: `Hash` for partition key, `Range` for sort key.
- **Lab implementation**:
  - Predefined dictionaries for table arguments (attribute definitions, key schema).
  - **Function `createTableDB`**: Unpacks arguments using `**kwargs` to pass to Boto3.

#### Example Table Definition

- **Thread table**:
  - Partition key: `Forum Name` (string).
  - Sort key: `Thread Subject` (string).

## Object Storage

### Object Storage Fundamentals

- **Object Storage**: Stores files as individual objects in a **flat structure** without traditional folder hierarchies (e.g., **Amazon S3** UI mimics folders for user familiarity).
- **Immutable objects**: Cannot be modified after initial write; updates require rewriting the entire object.
- **Versatile data support**: Stores CSV, JSON, text, images, binary data, etc., ideal for **semi-structured/unstructured data** (e.g., training ML models).

#### Key Components

- **UUID (Universal Unique Identifier)**: Unique key for object access and management.
- **Metadata**: Includes creation date, file type, owner, and other descriptive attributes.
- **Versioning**: Enables tracking multiple object versions under the same UUID.

### Benefits of Object Storage

- **Scalability**: Cloud-based solutions (e.g., S3) offer virtually limitless storage capacity.
- **High availability**: Data replicated across **multiple availability zones** (AZs) for disaster recovery.
- **Cost-effectiveness**: Cheaper than other storage options, especially for infrequently accessed data.
- **Durability**: **Amazon S3** provides "11 nines" (99.999999999%) data durability against failures.

### Cloud Object Storage Use Cases

- **Data lakes/lakehouses**: Foundation for flexible, scalable architectures due to schema-less design.
- **Disaster recovery**: Redundant storage across isolated physical data centers ensures data resilience.

### Amazon S3 Features

- **Flat storage with UI abstraction**: Folders are visual aids, not actual hierarchical structures.
- **Object versioning**: Preserves historical versions while updating objects.
- **Enterprise-grade reliability**: Designed for massive-scale, mission-critical applications.

## Logs

### Role of Logs

- **Logs** serve as append-only records of system/application events, ordered by time.
- Originally treated as **application exhaust** for monitoring/debugging, now recognized as valuable data sources.
- Enable **change data capture (CDC)** to track database modifications and trigger ingestion processes.
- Support downstream use cases: **user behavior analysis**, **anomaly detection**, performance monitoring, and automation.

#### Log Structure

- **Core components**:
  - **Actor identification**: User IDs, IP addresses, or service accounts associated with events.
  - **Event data**: Includes user actions (e.g., product added to cart) or system events (e.g., database updates).
  - **Timestamps**: Critical for maintaining chronological order and temporal analysis.
- Often categorized by **log levels** (debug, info, warn, error, fatal) to prioritize/classify records.

### Log Formats & Applications

- **Common formats**: Unstructured text, **JSON**, **CSV**, or binary-encoded data.
- **Key applications**:
  - Web server logs for **e-commerce analytics** (e.g., user navigation patterns).
  - Security system logs for **machine learning**-driven threat detection.
  - Infrastructure monitoring through error/fatal-level alerts.

### Importance for Data Engineers

- Essential for troubleshooting pipeline issues and monitoring system health.
- Enable **real-time data ingestion** strategies based on event triggers.
- Provide raw material for structured analytics and operational dashboards.
- Require understanding of parsing techniques, metadata extraction, and log-level filtering.

## Streaming Systems

### Key Terminology

- **Event**: A real-world action or state change (e.g., user click, sensor reading).
- **Message**: A record of information about an event (includes details, metadata, timestamps).
- **Stream**: A sequence of messages/events that can be processed in real time or in batches.

### Components of a Streaming System

#### **Event Producer**

- Generates or **produces** messages (e.g., IoT device, mobile app, website).
- Sends events to the **event router**, allowing asynchronous communication.

#### **Event Router (Streaming Broker)**

- Examples: **Apache Kafka**, **Amazon Kinesis**.
- **Before ingestion**: Buffers and filters events, distributing them to consumers.
- **Decouples** producers and consumers for scalability and fault tolerance.

#### **Event Consumer**

- Also known as the **subscriber**.
- Processes incoming messages in real time or as they become available.
- Multiple consumers can subscribe to the same stream for different purposes.

### Types of Streaming Systems

#### Message Queues

- **Event router** acts as a **queue** (FIFO: First-In, First-Out).
- Messages are **deleted** once read and acknowledged by the consumer.
- Ideal for **decoupled**, **asynchronous** microservices.
- Example: **Amazon SQS** (Simple Queue Service).

#### Streaming Platforms

- **Append-only** log of events retained for a certain period.
- Consumers read data **sequentially** but do **not** remove messages.
- Examples: **Apache Kafka**, **Amazon Kinesis Data Streams**.

### Applications in Data Engineering

- **Source systems** can be a simple event producer or a full event-driven architecture.
- Data engineers often build pipelines to **ingest**, **transform**, and **serve** streaming data.
- Persistent logs in streaming platforms facilitate **batch reprocessing** and **real-time** analytics.

# Connecting to Source Systems

## Overview

### Challenges in Connecting to Source Systems

- Common blockers include **IAM misconfigurations**, **networking errors**, and invalid **access credentials**.
- Troubleshooting connectivity issues is a **core data engineering skill**, often tested in interviews through broken pipeline scenarios.
- Requires understanding of **authentication protocols**, **network topology**, and cloud platform specifics.

### IAM and Security

- **IAM roles/permissions**: Critical for controlling access to cloud resources like databases and storage systems.
- **Security best practices**: Use least-privilege access, rotate credentials regularly, and audit permissions.
- **Shared Responsibility Model**: Cloud providers secure infrastructure; users secure data and access configurations.

### Networking in AWS

- **VPC (Virtual Private Cloud)**: Isolated network environment for AWS resources.
- **Subnets**: Partition VPCs into smaller networks for resource organization and security.
- **Security Groups & Routing**: Control inbound/outbound traffic and define network pathways between resources.

#### Core Networking Components

- **Endpoints**: Unique addresses (e.g., RDS database endpoints) to locate resources.
- **Gateways**: Facilitate communication between VPCs and external networks (e.g., internet or on-premises systems).

### Methods of Connecting to Source Systems

- **Console-based connections**: Quick for prototyping but lack repeatability due to UI changes.
- **CLI (Command Line Interface)**: Programmatic method for fetching connection details (e.g., database endpoints) and executing commands.
- **SDKs/APIs**:
  - **Boto3 (AWS SDK for Python)**: Used to create client connections (e.g., DynamoDB tables).
  - **JDBC/ODBC**: Standard APIs for database connectivity (e.g., MySQL via RDS).

#### SDKs and Automation

- Enable repeatable, traceable workflows (e.g., Jupyter notebooks for ingestion code).
- Examples: Connecting to RDS using endpoint/port/credentials or triggering Lambda functions via events.

### Troubleshooting and Real-World Application

- **Debugging pipelines**: Identify misconfigured IAM policies, network ACLs, or credential errors.
- **Practical labs**: Simulate real-world scenarios where broken connections require diagnosis and repair.
- **Key tools**: AWS CloudTrail for auditing, VPC Flow Logs for network monitoring, and CLI/SDKs for testing access.

## Connecting to an Amazon RDS MySQL Database

This optional reading item explains how to create an Amazon RDS database in your personal account and how you can connect to it through CloudShell or Python code.

### Setting up an RDS in your account

in most labs so far, you were given an instance of an Amazon RDS MySQL table to use. However, you can create your own RDS database instance in your personal account through the AWS management console as explained [here](https://aws.amazon.com/getting-started/hands-on/create-mysql-db/). In the upcoming weeks, you will learn how to create an RDS database programmatically using Terraform.

### How to connect to an RDS instance?

After you create your own public instance of an Amazon RDS database, you need to establish a connection to the database server to query it. In this example, the Amazon RDS database we are connecting to is MySQL, and the following information is needed:

1. Database hostname/endpoint (address or location of the database server)
2. Database port (the network port the MySQL server is running on)
3. Database username & password (credentials to log in to the database)

You can get the hostname/endpoint and port from the AWS management console or programmatically from the command line interface (CLI) after you create the table. You would have created the database username & password when setting up the database instance. Otherwise, ask the database administrator for this information.

### Connecting to the database through AWS CloudShell

AWS CloudShell is a browser-based shell providing command-line access to your AWS resources in the selected region. To connect to MySQL database through the console, you can use the following command ([link to documentation](https://dev.mysql.com/doc/refman/8.0/en/connecting.html))

```sh
mysql --host=[hostname]
 --port=[port number]
 --user=[database user name]
 --password=[database user password]
```

This command is specific to MySQL. Each DBMS specifies how to connect to its database through the command line. For example, here's [the documentation](https://www.postgresql.org/docs/9.1/app-psql.html) for connecting to a PostgreSQL database.

The endpoint and port number were manually entered, but you could get them programmatically using this [describe-db-instances](https://docs.aws.amazon.com/cli/latest/reference/rds/describe-db-instances.html) command:

```sh
aws rds describe-db-instances --filters "Name=engine,Values=mysql" --query "*[].[DBInstanceIdentifier,Endpoint.Address,Endpoint.Port,MasterUsername]"
```

(Note: It is not good practice to share these credentials publicly. This table was created for this reading material and has been deleted.)

After you establish the connection, you can send your queries to the database using SQL.

In the commands below, we first checked the available databases, then selected one. We checked the tables within that database and performed a “select query” on the "pet" table.

![aws-cloudshell-mysql](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/aws-cloudshell-mysql.png)

To exit the connection, you can type `exit` or `\q`. (Note: to create your own tables, check lab 1 of this week or the [MySQL documentation](https://dev.mysql.com/doc/refman/8.0/en/create-database.html)).

### Connecting to the database through Python

To connect to MySQL database using Python, first install [pymysql](https://pymssql.readthedocs.io/en/stable/). `pymysql` allows you to establish a connection to a MySQL database in your Python code using the `.connect()` method.

You need to specify the following pieces of information:

- Database hostname/endpoint (address/location of the database server)
- Database port
- Database username & password (credentials to connect to the database)
- Database name

You can get the port and endpoint programmatically in Python using the AWS software development kit (SDK) [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html). It allows you to connect to your provisioned resources and extract the necessary parameters.

![aws-sdk-boto3-port-endpoint](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/aws-sdk-boto3-port-endpoint.png)

The second cell in the image above shows how to set the access and secret access keys. These keys are generated for any AWS IAM user as long-term credentials to programmatically connect to AWS resources. However, it is not best practice to include these credentials in your code. For best practice, you should save these keys in a config file. Check [here](https://wellarchitectedlabs.com/common/documentation/aws_credentials/) for other options.

To get the parameters in 'dbInstance', you can run '`dbInstance`'. The output is shown below.

![dbInstance-parameters](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/dbInstance-parameters.png)

Once you have the necessary parameters, you can establish a connection to the database using `pymysql.connect()`, and then you can perform your SQL request.

![pymysql-connect](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/pymysql-connect.png)

### Final Remark

If you created an RDS database instance for practice, please remove it when you are done.

From the RDS service page, click on "Databases" in the left-hand menu, select the database you just created, and delete it (you can find the delete option in the "Action" drop-down menu or by right-clicking on the database)

![rds-databases-menu](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/rds-databases-menu.png)

## Basics of IAM and Permissions

### Importance of IAM

- **IAM** ensures secure and controlled access to sensitive data.
- Protects against data breaches caused by **human error** and **misconfigurations**.
- Implements the **principle of least privilege** to grant only the required access.

### Core IAM Concepts

- **Permissions**: Define which actions an identity (user or application) can perform on specified resources.
- **Identities**: Users, groups, or services that need access to resources.
- **Resources**: Objects like databases, ETL tools, or **Amazon S3** buckets.

#### Common IAM Components

- **Root User**: Unrestricted access to all resources in the **AWS** account.
- **IAM Users**: Individuals with specific permissions (e.g., a junior data engineer).
- **IAM Groups**: Collections of users sharing a set of permissions (e.g., a _Data Engineers_ group).
- **IAM Roles**: Temporary access rights assumed by a user or service (e.g., **Amazon EC2** instance accessing **Amazon S3**).

### IAM Policies

- **Definition**: JSON documents detailing the allowed actions on specific resources.
- **Actions**: Specify operations like **Get**, **List**, or **Write** on services (e.g., **AWS Glue**).
- **Star (\*)** in resources or actions: Wildcard indicating partial or complete pattern matching.

#### Example Policy Snippet

- Allows access to any **Amazon S3** bucket starting with `DLAi_data_engineering*`.
- Grants **list** or **get** actions for matching **S3** buckets.
- Permits all **AWS Glue** actions (`glue.*`) on a specified resource.

### Best Practices

- **Minimize privileges**: Grant only the necessary permissions for the required duration.
- **Avoid** storing credentials in public or unsecured locations (e.g., GitHub, public **Amazon S3**).
- **Use IAM roles** instead of long-term credentials for services (e.g., **Amazon EC2**).
- **Regularly review** policies, rotate keys, and monitor **access logs** to prevent unauthorized access.

## Basics of AWS IAM

### What is IAM?

AWS IAM is a web service that helps you manage and securely control access to your AWS resources and services. With IAM, you can centrally manage who is authenticated in your Account and what resource permissions they have. Using IAM, you can share your resources without sharing your credentials, and you can select specific actions people can access at a granular level. It’s a global service available at no additional cost, meaning you can see and use your IAM configurations from any region in the AWS Management Console.

### What is an IAM user?

When you create an account on AWS, you begin with the “root user” identity, which has full access to all AWS resources and services in the account. It is strongly recommended that you don’t perform daily operations using this account. Instead, create an admin user for everyday tasks. Whether you’re the root or admin user, you can create other users in your account to allow people in your organization to access AWS resources.

IAM users are created under your AWS account, so you don't need separate accounts for IAM users. Each user could be a person or service that interacts with AWS resources. When you create a user, you define what resources the IAM user can access, and what actions they can perform. AWS will then generate a set of credentials for that user. The credentials could be a username and password for accessing the AWS management console, or they it be an access keys for programmatic access to AWS resources. IAM user credentials are long-term credentials as they stay with the user until the admin rotates them. When you provide users with their own login credentials, you help prevent the sharing of credentials. You can add more users to your account, and all user activities are billed to your account.

By default, a new user does not have any permission to access any AWS resources. You can grant them access to AWS resources by attaching policies to them. A policy specifies what actions are allowed or denied for a given resource (read only, write only, full access). A policy can be attached to multiple users, and a user can have multiple policies. You can choose AWS-managed policies or create your own custom policies. Whenever a user makes a request, AWS evaluates their policies to determine if that request is allowed.

For example, suppose you’re working with a data scientist and want to grant them read-only access to an S3 bucket to extract the training data set. The figures below show the steps to create this user.

1. Create a new user

![iam-create-a-new-user](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/iam-create-a-new-user.png)

2. Create the credentials for this user

![iam-user-credentials](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/iam-user-credentials.png)

3. Set the permissions for this user by attaching an existing policy or creating a new one. (For more information, see the **What is an IAM policy?** section below)

![iam-policy](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/iam-policy.png)

4. Review the user details and create the new IAM user

![iam-review-user-details](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/iam-review-user-details.png)

5. Share the login credentials with the user

![iam-share-login-credentials](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/iam-share-login-credentials.png)

### What is an IAM group?

Now, what if you want to grant the same permissions to more than one user, maybe a team of data scientists who want to access the same resources with the same level of permissions. You could attach the same policy to each user, but it might be hard to manage as the team grows. In this case, you can create an IAM group, which is a collection of users, and then attach the policy to the group rather than individual users. Each user in the group inherits the group's permissions. Think of the IAM group as a way to organize permissions. Here are some features of IAM groups:

- Groups can have multiple users
- A user can belong to no group, one group, or multiple groups (up to 10 groups)
- Groups cannot be nested

### What is an IAM role?

The third IAM identity is a role. An IAM role has specific permissions with short-term credentials. Roles can be assumed by entities, like people, applications, or trusted AWS resources. IAM roles don't have long-term credentials. Instead, they provide temporary security credentials for the duration of the role session. You first create an IAM role and attach a policy to it. Then you specify which resource can assume this role. This temporarily grants permissions to AWS resources.

**Example 1**: Let’s say you run a code on an EC2 instance that needs to read from S3. By default, the EC2 instance does not have permission to read from S3. You can transfer your credentials to EC2, but this is not secure. A better approach is to create a role, attach the required policy to read from S3, and allow the EC2 instance to assume this role.

**Example 2**: Let’s say you run a Glue ETL job and want it to write the ingested and transformed data to S3. You can create a role with permissions to write to S3, then allow Glue ETL to assume this role.

### What is an IAM Policy?

You can manage access in AWS by creating policies and attaching them to IAM users, groups, or roles.

“A policy is an object in AWS that defines the permissions of the attached user or role. AWS evaluates these policies when an IAM user or role makes a request. Permissions in the policies determine whether the request is allowed or denied. Most policies are stored in AWS as JSON documents.” - [AWS IAM documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html)

You can use an AWS-managed policy or create your own custom policy.

**Example: AWS-managed policy (AmazonS3FullAccess)**

Here's the AmazonS3FullAccess managed policy that grants full access to S3.

![aws-managed-policy-AmazonS3FullAccess](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/aws-managed-policy-AmazonS3FullAccess.png)

- **Version** – Specify the version of the policy language that you want to use.
- **Statement** – Use this element as a container for the details of some given permissions or denials. You can include more than one statement in a policy. If a policy includes multiple statements, AWS applies a logical OR across the statements when evaluating them.
  - **Sid** (Optional) – Include a statement ID to differentiate between your statements.
  - **Effect** – Use Allow or Deny to indicate whether the policy allows or denies access.
  - **Action** – Include a list of actions the policy allows or denies. In this example, the allowed actions on S3 are “`*`”, meaning all read and write actions on s3 are allowed.
  - **Resource** – An object or a list of objects to which the actions apply. For example, in the case of S3, you can specify which bucket is allowed or denied access. In this example, the resource element is "`*`", meaning all resources.

**Example: Customer managed policy**

Here’s another example of a policy that allows read and write access to all S3 buckets, except the bucket “confidential”, where deletion is denied.

![aws-customer-managed-policy](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/aws-customer-managed-policy.png)

### Learn more

- [Sample S3 bucket policies](https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies.html)
- [IAM User Guide (Access management for AWS resources)](https://docs.aws.amazon.com/IAM/latest/UserGuide/access.html)
- [What is IAM?](https://docs.aws.amazon.com/IAM/latest/UserGuide/id.html)

## Basics of Networking in the Cloud

### Global AWS Infrastructure

- **Physical Data Centers**: Located in various global regions, each with multiple **availability zones**.
- **Regions** vary in **cost**, **latency**, and **compliance** requirements.
- **Replication** across regions and availability zones improves **redundancy** and **disaster recovery**.

### Virtual Private Clouds (VPCs)

- **Amazon Virtual Private Cloud (VPC)**: Creates an isolated network spanning multiple availability zones within a region.
- **Subnets**: Partition the VPC for finer control (e.g., **public** subnets for web servers, **private** subnets for databases).
- **Network ACLs**: Define security rules at the subnet level.
- **Internet Gateways**: Route traffic to and from the internet as needed.

#### Key Considerations

- **Before deployment**: Choose regions that meet legal, latency, and cost constraints.
- Understand how **VPCs**, **subnets**, and **gateways** connect to ensure correct data flow.
- Complex configurations require attention to both **network settings** and **IAM permissions**.

### Impact on Data Pipelines

- Networking choices affect **reliability**, **availability**, and **performance** of pipelines.
- Proper network design is critical for connecting to **source systems** and for **pipeline orchestration**.
- Mistakes in routing or security settings can block data flow or create vulnerabilities.

## AWS Networking Overview - VPC

### VPC

A VPC (Virtual Private Cloud) is an isolated private network where you can launch your AWS resources. A VPC exists inside a region and can span multiple availability zones. A region can contain multiple VPCs: each region comes with a preconfigured VPC, known as the default VPC, that you can use to launch your resources, or you can create your own custom VPC within the same region.

![vpc-region-availability-zone](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/vpc-region-availability-zone.png)

Launching resources such as EC2 instances or RDS databases within a VPC enables them to interact with other resources in the VPC. However, a custom VPC, by default, does not allow communication with the public internet or other VPCs. You can configure the VPC settings to allow connectivity between VPCs or between a VPC and the internet. Note that AWS provides a default VPC, which is already set up for public internet access.

Learn more

For more information about the default VPC and how to create your custom VPC, see the [AWS documentation](https://docs.aws.amazon.com/vpc/latest/userguide/default-vpc.html).

### Internet Gateway

An internet gateway enables resources created inside a public subnet to send and receive traffic from the public internet. It allows both inbound and outbound traffic, connecting resources within a public subnet to the internet and allowing outside resources to connect to your resources. You can attach only one internet gateway to each VPC. That's because behind the scenes, the internet gateway cloud service is supported by a distributed infrastructure, with built-in redundancy and high availability. AWS will also automatically scale the gateway's capacity up or down to handle varying loads of traffic.

Note that resources that are created within a public subnet should have two types of IP addresses: one private IP address used to communicate with resources within the same VPC and another public IP address that allows outside resources to connect to them. You would need to enable each resource in a public subnet to have a public address.

[Internet Gateway](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html) (AWS Documentation)

![internet-gateway](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/internet-gateway.png)

### NAT Gateway

Resources in a private subnet are hidden from the internet, preventing outside connections and protecting them from attacks and unauthorized access (unsolicited connection requests are not allowed). However, resources in a private subnet can establish a one-way connection to the internet for outgoing requests (e.g., to download an update or send an email). You can enable this one-way connection by using a NAT gateway (Network Address Translation service). You launch a NAT gateway inside a public subnet and then the NAT gateway can work with the internet gateway to allow resources in a private subnet to connect to the internet. When a private resource sends an outgoing request, the NAT gateway replaces the resource's private address with its own address. To send the response traffic to the private resource, the NAT gateway translates the address back to the original source address. NAT gateways are not available in the free-tier AWS account.

[NAT Devices](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat.html) (AWS Documentation)

![nat-gateway](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/nat-gateway.png)

### Route Table

Each time a resource within a subnet generates a request, that request will contain the IP address of the destination that it wants to reach. The request needs additional direction to know where to go. For example, does it need to stay in the local network or should it go through a gateway? All of this additional information can be expressed as a set of rules, called routes, that determine where network traffic from your subnet is directed. These routes are stored in a route table. So you can think of a route table as a collection of street signs that direct the traffic generated from a subnet to reach its destination.

When you create a VPC, a route table called the main route table is automatically created. This table assumes that traffic should flow between the resources within the same VPC, so by default it contains a route that directs any traffic with a destination IP address within the VPC CIDR block to the local network. In addition to the main route table, you can create custom route tables for the same VPC and associate them with particular subnets. A common practice is to create at least two route tables: one that you associate with public subnets and another one that you associate with private subnets. By default, any custom table that you create will have the local route already inside it, and you can add additional routes to it. If a subnet is not associated with any custom route tables, it uses the main route table. Here's an example:

[Route Table](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html) (AWS documentation)

![route-table](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/route-table.png)

In this example, each subnet is associated with a different route table. The destination column represents the destination IP address to which a request is sent from, and the target column represents how or through what component the traffic should be routed. In route table 1 that's associated with the public subnet, the first row means that any traffic sent to an IP address within 10.0.0.0/16, which is the VPC CIDR block, is routed inside the local VPC. Otherwise, if the IP address does not match any address within 10.0.0.0/16, it is routed to the internet gateway.

### Network ACL

You can protect your resources from unauthorized access by choosing private subnets and ensuring proper routing. To add additional security to your subnets, you can also set up a firewall that filters traffic to and from your subnets; this is done by using network ACLs (access control lists) to explicitly mention what traffic is allowed to enter or leave a subnet. A network ACL consists of a list of rules that specify which inbound or outgoing traffic is allowed or denied. It is created at the VPC level and can be associated with specific subnets. When you create a VPC, a default network ACL is automatically created. You can add custom inbound and outbound rules to this network ACL or even create your own custom network ACLs and associate them with specific subnets. Network ACLs help control the flow of traffic within a VPC between subnets as well as to/from the public internet.

**Here's what the default network ACL looks like:**

| Inbound |                  |          |            |           |            |
| :-----: | :--------------: | :------: | :--------: | :-------: | :--------: |
| Rule #  |       Type       | Protocol | Port Range |  Source   | Allow/Deny |
|   100   | All IPv4 traffic |   All    |    All     | 0.0.0.0/0 |   ALLOW    |
|   \*    | All IPv4 traffic |   All    |    All     | 0.0.0.0/0 |    DENY    |

| Outbound |                  |          |            |           |            |
| :------: | :--------------: | :------: | :--------: | :-------: | :--------: |
|  Rule #  |       Type       | Protocol | Port Range |  Source   | Allow/Deny |
|   100    | All IPv4 traffic |   All    |    All     | 0.0.0.0/0 |   ALLOW    |
|    \*    | All IPv4 traffic |   All    |    All     | 0.0.0.0/0 |    DENY    |

It is configured to allow all incoming traffic to flow into the subnets, and all outgoing traffic to flow out of the subnets. The last rule whose rule number is an asterisk (\*) is always included in any network ACL: it ensures that if a request doesn't match any of the other numbered rules, it's denied. You can't modify or remove this rule.

Here's an example of a custom network ACL:

![custom-network-acl](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/custom-network-acl.png)

Rules are evaluated in ascending order according to the rule number until a match is found. If no match is found then the final rule (\*) is applied.

### Security Groups

While a network ACL acts as a firewall that filters traffic to and from your subnets, a security group acts as a firewall for a specific EC2 instance to control incoming and outgoing traffic for that specific instance. It adds an additional layer of security for any of your resources that run on your EC2 instances, and allows you to specify inbound rules (to control incoming traffic to your instance) and outbound rules (to control outbound traffic from your instance).

![security-groups](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/security-groups.png)

**Reference**: [Compare security groups and network ACLs](https://docs.aws.amazon.com/vpc/latest/userguide/infrastructure-security.html#VPC_Security_Comparison)

By default, all outbound traffic from your instance is allowed and all in-bound traffic to your instance is denied. When you create an EC2 instance or after you launch it, you can modify the in-bound rules to allow certain types of traffic from certain IP addresses at certain ports. Here's an example of some inbound rules that can be edited from the AWS management console.

![edit-inbound-rules](/data-engineering/deeplearning.ai-data-engineering-professional-certificate/02-source-systems-data-ingestion-and-pipelines/assets/edit-inbound-rules.png)

When you create an inbound rule, you must specify the following:

- The protocol (e.g. SSH, HTTP, HTTPs, etc.), which defines the type of traffic allowed. For more info about these protocols, you can check [here](https://www.cdw.com/content/cdw/en/articles/networking/types-of-network-protocols.html).
- The range of ports to allow (depending on the protocol, the port number can be automatically assigned). For more info about port numbers, you can check [here](https://www.cloudflare.com/learning/network-layer/what-is-a-computer-port/).
- The traffic source to allow for inbound rules (the IP address of the source).

- [Control traffic to subnets using network ACLs](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html)
- [Create a security group](https://docs.aws.amazon.com/en_us/console/ec2/security-groups/create)
- [Security group rules](https://docs.aws.amazon.com/en_us/console/ec2/security-groups/reference)

### Endpoints (optional)

There are two types of AWS services: private zone services and public zone services.

- Private zone services offer resources that need to be launched within a VPC. These services include Amazon EC2, RDS (Relational Database Service), ELB (Elastic Load Balancer), and EFS (Elastic File System).
- Public zone services offer resources that do not need to be launched within a VPC. Instead, these resources are accessed using public endpoints (i.e. public IP addresses). These services include Amazon S3, Amazon DynamoDB, AWS Lambda, Amazon Kinesis, and Amazon Athena.

You can use an internet gateway and NAT gateway to allow resources in the subnets to access public services, just as they connect to the public internet. But what if you want these resources to only connect to AWS public services? You can still use gateways, but AWS offers another option: endpoints.

- Interface endpoints can be placed in a public subnet or private subnet to allow resources in these subnets to connect to AWS public resources.
- Gateway endpoints can be attached to a VPC to allow the resources in the VPC to connect to S3 and DynamoDB. (S3 can also be reached using an interface endpoint, but DynamoDB can only be reached using gateway endpoint).

- [What are VPC endpoints?](https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/what-are-vpc-endpoints.html)
- [How two VPCs can communicate with each other - What is VPC peering?](https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html)

## Troubleshooting AWS Network Connectivity

### VPC and Subnets

- **Amazon Virtual Private Cloud (VPC)** provides isolated private networks on AWS.
- **Route tables**: Determine traffic flow within the VPC and to external networks.
- **Public subnets**: Use route tables pointing to an **Internet Gateway** for public internet access.
- **Private subnets**: Use route tables pointing to a **NAT Gateway** for secure outbound-only internet access.
- Subnet classification (public/private) depends entirely on route table configuration, not subnet creation.

### Security Groups

- **Stateful virtual firewalls**: Control inbound/outbound traffic at the instance level.
- **Inbound rules**: Must be explicitly defined; return traffic is automatically allowed.
- **Outbound traffic**: Permitted by default, making inbound rule configuration the primary focus.

### Network ACLs

- **Stateless subnet-level firewalls**: Require explicit inbound **and** outbound rules.
- Provide additional security layer with granular control for subnet-wide traffic filtering.
- Used for enforcing specific security requirements beyond instance-level protections.

### Troubleshooting Steps

- **VPC verification**: Ensure an Internet Gateway is attached and functional.
- **Route tables**: Confirm correct routes (e.g., public subnets → Internet Gateway, private subnets → NAT Gateway).
- **Subnet associations**: Validate route tables are properly linked to subnets.
- **Security groups**: Check inbound rules allow required traffic types/ports.
- **Network ACLs**: Verify both inbound and outbound rules permit necessary traffic.
- **Instance configuration**: Ensure instances are in correct subnets and associated with proper security groups.

# Week 1 Quiz

## Questions

1. Which of the following represents a source system that contains structured Data?
   1. A video file of a lecture.
   2. A relational database containing customer information, where each row represents a customer and each column represents a customer attribute such as name, address, and phone number.
   3. A collection of customer feedback saved in a text file.
   4. A JSON file containing user profiles, where each profile lists attributes like "firstName", "lastName", and "address" in a key-value format.
2. What does CRUD stand for?
   1. Compute, Retrieve, Upload, Download
   2. Copy, Replace, Undo, Destroy
   3. Create, Read, Update, Delete
   4. Connect, Receive, Utilize, Disconnect
3. What is a database management system (DBMS)?
   1. A DBMS is the set of rules that defines how to write queries to access data in a database.
   2. A DBMS is an API that standardizes the connection to any type of database.
   3. A DBMS is the software layer that sits on top of the physical database storage and allows you to manage and interact with the data.
   4. A DBMS is a graphical user interface that illustrates the database content.
4. According to this week’s videos, what are the benefits of applying normalization to relational databases? Select all that apply.
   1. Improves data query (i.e. retrieval) speed
   2. Minimizes redundancy
   3. Ensures data integrity
5. Which of the following statements about primary and foreign keys is true?
   1. A foreign key of a table can reference the primary key of another table.
   2. A foreign key is a secondary key that helps the primary key uniquely identify each row in its own table.
   3. A primary key and a foreign key are the same and serve the same purpose in a database.
   4. Primary keys are used in relational databases and foreign keys are used in NoSQL databases.
6. Which of the following statements about relational databases and NoSQL databases is true?
   1. Relational databases operate under the principle of strong consistency, while NoSQL databases operate under the principle of eventual consistency.
   2. Relational and NoSQL databases are both typically ACID compliant
   3. Relational databases do not have to follow a strict schema like NoSQL databases.
   4. Complex join operations are supported by both relational and NoSQL databases.
7. You’ve learned about the four principles of ACID compliance: atomicity, consistency, isolation, and durability.
   1. Which of the following represents a scenario that demonstrates the isolation principle?
   2. A bank transaction that moves money from Account A to Account B should run with updates to both account balances or fail without updating either account balance.
   3. The data stored in a bank transaction database will never be lost, even when there’s a power loss.
   4. Given that an account balance is $20, if two transactions each deducting $10 from the account occurred at the same time, the account balance will be $0 not $10 after the two transactions are completed.
   5. If there is a constraint that the bank balance should be a positive integer, any transaction that will make the balance go below zero should fail.
8. Which of the following source systems can store unstructured data? Select all that apply.
   1. Key-value store
   2. Document store
   3. Object storage
   4. File system
9. Which of the following statements is true about logs?
   1. Logs store a sequence of records in a random order.
   2. Many database systems will have logs that you can use to track changes in the database.
   3. Logs only contain error messages that are generated by an application.
   4. Logs are used to support downstream analytics use cases but not machine learning use cases.
10. Message queues and event-streaming platforms are both examples of event-streaming architectures. Which of the following statements best describe the similarities between the two? Select all that apply.
    1. Both architectures are based on asynchronous communication between an event producer and an event consumer.
    2. They both use a log-based router that relay messages from an event producer to an event consumer.
    3. They both provide persistent storage for the streamed events.
    4. You could encounter them as source systems or use them as ingestion tools.
11. Which of the following statements is true about IAM users and IAM roles?
    1. An IAM role can be assumed by any resource, user, or application.
    2. An IAM user is someone who assumed an IAM role
    3. An IAM user has temporary security credentials, whereas an IAM role is assigned long-term credentials.
    4. Policies are only attached to IAM users.
12. Which of the following statements is true about how traffic is managed within a Virtual Private Cloud (VPC)?
    1. Resources created in a private subnet can send requests to outside resources through a NAT gateway.
    2. Within the same VPC, resources created in a public subnet cannot automatically communicate with resources created in a private subnet.
    3. Resources from two different VPCs can communicate with each other by default.
    4. Resources created in a public subnet can automatically interact with the public internet.

## Answers

1. 2
   1. Relational databases store structured data organized into rows and columns.
2. 3
   1. CRUD is a transactional pattern indicating that data needs to first be created, then you can read, update, and delete the data.
3. 3
4. 2 & 3
5. 1
   1. Foreign keys are used to establish relationships between tables by referencing the primary key or a unique column of another table.
6. 1
7. 3
   1. Isolation ensures that when several clients try to execute transactions concurrently, each transaction is executed independently in sequential order.
8. 3 & 4
   1. Key-value stores contain semi-structured data stored as key-value pairs.
   2. Document stores contain semi-structured data stored in document format.
   3. Object storage can store unstructured data, such as audio, video, and text files.
   4. File systems can store unstructured data, such as audio, video, and text files.
9. 2
   1. These logs help you track changes through a process known as change data capture, or CDC.
10. 1 & 4
    1. Both architectures rely on the presence of an event router or message broker that acts as a buffer between the event producer and the event consumer. The router helps decouple the producer from the consumer, which enables asynchronous communication between them, meaning that the producer can send messages to the router or broker at any time and doesn't have to wait for the consumers to consumer the messages.
    2. When you work with event systems as a source system, it could be that your upstream source is a simple event producer, like an IoT device, and your system, or the system you build rather, comprises both the event router and consumer. Or it could be that your upstream source system is made up of multiple producers, routers, and consumers and the systems you build are effectively just another downstream consumer of events.
11. 1
    1. A resource, user, or application can temporarily assume an IAM role to access AWS resources.
12. 1
