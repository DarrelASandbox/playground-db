- [Serving Data for Analytics and Machine Learning](#serving-data-for-analytics-and-machine-learning)
  - [Week 4 Overview](#week-4-overview)
    - [Course Recap](#course-recap)
    - [Serving Data for Analytics](#serving-data-for-analytics)
    - [Serving Data for Machine Learning](#serving-data-for-machine-learning)
    - [Semantic Layer](#semantic-layer)
    - [Data Serving Methods](#data-serving-methods)
    - [Final Week Overview](#final-week-overview)
  - [Serving Data for Analytics and Machine Learning](#serving-data-for-analytics-and-machine-learning-1)
    - [Methods for Serving Data](#methods-for-serving-data)
    - [Data Management](#data-management)
    - [Semantic Layer](#semantic-layer-1)
    - [Data Consumption](#data-consumption)
  - [Views and Materialized Views in Databases](#views-and-materialized-views-in-databases)
    - [Views](#views)
      - [Common Table Expressions (CTEs) vs. Views](#common-table-expressions-ctes-vs-views)
      - [Limitations of Views](#limitations-of-views)
    - [Materialized Views](#materialized-views)
    - [Lab Overview](#lab-overview)
- [Course Capstone Project](#course-capstone-project)
  - [Summary of the Program Concepts](#summary-of-the-program-concepts)
    - [Program Overview](#program-overview)
    - [Thinking Like a Data Engineer](#thinking-like-a-data-engineer)
    - [Data Ingestion](#data-ingestion)
    - [Data Transformation](#data-transformation)
    - [Data Warehouses vs. Data Lakes vs. Data Lakehouses](#data-warehouses-vs-data-lakes-vs-data-lakehouses)
    - [Data Engineering Undercurrents](#data-engineering-undercurrents)
    - [Capstone Lab](#capstone-lab)
  - [Lab Walkthrough - Capstone Project (Part 1)](#lab-walkthrough---capstone-project-part-1)
    - [Project Overview](#project-overview)
    - [Business Problem: De Ftunes Music Streaming Service](#business-problem-de-ftunes-music-streaming-service)
    - [Available Data Sources](#available-data-sources)
    - [Data Modeling \& Storage Requirements](#data-modeling--storage-requirements)
    - [Data Modeling Approach: Star Schema](#data-modeling-approach-star-schema)
    - [Data Pipeline Architecture](#data-pipeline-architecture)
      - [Terraform Configuration](#terraform-configuration)
    - [Lab Tasks (Part 1)](#lab-tasks-part-1)
    - [Next Steps (Part 2)](#next-steps-part-2)
- [Week 4 Quiz](#week-4-quiz)
  - [Questions](#questions)
  - [Answers](#answers)
- [Summary, Resources \& Acknowledgements](#summary-resources--acknowledgements)
  - [The Future of Data Engineering](#the-future-of-data-engineering)
    - [Evolving Roles in Data](#evolving-roles-in-data)
    - [Future of Data Engineering Tools and Technologies](#future-of-data-engineering-tools-and-technologies)
    - [AI Integration in Data Engineering](#ai-integration-in-data-engineering)
    - [Advice for Aspiring Data Engineers](#advice-for-aspiring-data-engineers)
    - [Final Thoughts](#final-thoughts)
  - [Interview with Zach Wilson: Data Engineering Insights](#interview-with-zach-wilson-data-engineering-insights)
    - [Introduction](#introduction)
    - [Getting Your First Data Engineering Job](#getting-your-first-data-engineering-job)
    - [Key Skills for Data Engineers](#key-skills-for-data-engineers)
    - [Becoming a Good Data Engineer](#becoming-a-good-data-engineer)
    - [Advice to Younger Self](#advice-to-younger-self)
    - [Staying Up-to-Date](#staying-up-to-date)
    - [Determining Value in Work](#determining-value-in-work)
      - [Example of Leveraged Impact](#example-of-leveraged-impact)
    - [Future of Data Engineering](#future-of-data-engineering)
    - [AI Impact and Hybrid Roles](#ai-impact-and-hybrid-roles)
  - [Career Advice for Data Professionals with Carly Taylor](#career-advice-for-data-professionals-with-carly-taylor)
    - [Introduction](#introduction-1)
    - [Carly's Journey into Data](#carlys-journey-into-data)
    - [A Day in the Life of a Machine Learning Engineer (at Activision)](#a-day-in-the-life-of-a-machine-learning-engineer-at-activision)
    - [Data Engineer vs. Machine Learning Engineer](#data-engineer-vs-machine-learning-engineer)
    - [Machine Learning Applications at Call of Duty](#machine-learning-applications-at-call-of-duty)
    - [Transitioning from Individual Contributor to Leadership](#transitioning-from-individual-contributor-to-leadership)
    - [Advice to Younger Self](#advice-to-younger-self-1)
      - [T-Shaped Knowledge Explained](#t-shaped-knowledge-explained)
    - [Advice for Getting the First Job in Data](#advice-for-getting-the-first-job-in-data)
    - [Standing Out in a Competitive Job Market](#standing-out-in-a-competitive-job-market)
    - [Final Advice](#final-advice)
  - [Interview with Ben Rogojan (Seattle Data Guy)](#interview-with-ben-rogojan-seattle-data-guy)
    - [Introduction](#introduction-2)
    - [Ben's Journey](#bens-journey)
    - [Early Days as a Data Engineer](#early-days-as-a-data-engineer)
    - [Experience at Facebook](#experience-at-facebook)
    - [Importance of Communication and Problem-Solving](#importance-of-communication-and-problem-solving)
    - [Advice for Aspiring Data Engineers](#advice-for-aspiring-data-engineers-1)
    - [On Learning About Business](#on-learning-about-business)
    - [Real-Time Data Expectations](#real-time-data-expectations)
    - [Excitement and Hopes for the Future](#excitement-and-hopes-for-the-future)
    - [Finding Ben Rogojan](#finding-ben-rogojan)

# Serving Data for Analytics and Machine Learning

## Week 4 Overview

### Course Recap

- Covered data modeling for analytics and machine learning.
- Discussed tools and technical considerations for data transformation.

### Serving Data for Analytics

- **Business Analytics**: Serving data from a **data warehouse** or **data lake** for dashboards, reports, and ad hoc analysis.
- **Operational Analytics**: Serving data with required latency to monitor immediate trends and inform immediate action.
- **Embedded Analytics**: Serving data to client-facing data products or dashboards.

### Serving Data for Machine Learning

- Collaboration with **data scientists** or **machine learning engineers**.
- Focus on data acquisition, transformation, and delivery for model training.
- Examples covered previously: **Customer churn model**, **recommendation system**.

### Semantic Layer

- Incorporating business definitions and data logic.
- Documenting definitions (e.g., "active user") and deriving business metrics (e.g., revenue).
- Creating common language for served data.

### Data Serving Methods

- Serving data as a **table**, **view**, or **materialized view**.
- Practice creating views using **DBT** in the first lab.

### Final Week Overview

- Details of serving data.
- Summary of data engineering concepts learned.
- Revisiting the data engineering lifecycle and framework.
- Capstone lab: Applying all concepts learned throughout the program.

## Serving Data for Analytics and Machine Learning

### Methods for Serving Data

- **Sharing data as files**:
  - **Use Case**: Data scientists need text files, analysts need CSV files, machine learning engineers need images.
  - **Mechanism**: Email, data sharing platforms, object storage, data lake.
    - **Data sharing platforms**: Help ensure coherent and consistent version of files.
    - **Object storage/Data Lake**: For sharing large semi-structured or unstructured data.
  - **Limitations**: Difficult to manage versioning, hard to scale beyond single files.
- **Serving data from OLAP database or data warehouse**:
  - **Use Case**: Analysts/data scientists query using **SQL** or another query language.
  - **Benefits**: Enforces schema, fine-grained permission controls (table, column, row level), high performance for complex queries.
  - **Limitations**: May not be suitable for streaming data.
- **Streaming systems**:
  - **Use Case**: Serving data in real-time.
  - **Example**: **Operational analytics databases** combine features of OLAP database and stream processing for low-latency analytical queries.

### Data Management

- Ensure stakeholders trust and correctly interpret the data.
- **Data definitions**: Meaning of data, documented and accessible (e.g., definition of "customer").
- **Data logic**: Formulas for deriving metrics, detailing statistical calculations (e.g., gross sales, customer lifetime value).

### Semantic Layer

- Translates underlying data elements and structures into intuitive business terms.
- Ensures a single consistent definition for each business term.
- Can reside in a **BI tool** or created using tools like **DBT** (using YAML files and SQL queries for standard business metrics).

### Data Consumption

- End users use **visualization tools** or **business intelligence platforms** (e.g., **Amazon QuickSite**, **Apache Superset**, **Looker**) to create dashboards.
- Data scientists use notebooks for data exploration, feature engineering, model training.
- Managing Cloud platforms designed for data science workloads (e.g., **Amazon Sagemaker**, **Google Cloud Vertex AI**, **Microsoft Azure Machine Learning**).

## Views and Materialized Views in Databases

### Views

- Serve data as table-like objects in addition to tables.
- **Creation**: `CREATE VIEW view_name AS query`.
- **Virtual table**: A view represents a virtual table, not a physical one.
- **On query**: The database creates a new query that combines the view with the referencing query.
- **Simplifies complex queries**: Allows stakeholders to easily access common queries. Example: Combining multiple tables into a wide table.
- **Security**: Can restrict data access by selecting specific columns and rows.

#### Common Table Expressions (CTEs) vs. Views

- **CTEs**: Similar to views; created using the `WITH` clause.
- **Scope**: CTEs exist only within the scope of the main query. Discarded after execution.
- **Views**: Actual database objects accessible by external users. Persist in the database until explicitly dropped.
- **Persistence**: Views can be referenced across different sessions and queries.

#### Limitations of Views

- **No precomputation**: The query represented by the view needs to be executed every time it’s referenced. Can be expensive for complex queries.

### Materialized Views

- **Precomputation**: Performs some or all of the view computations in advance.
- **Caching**: Caches the query results.
- **Refresh**: Allows periodic data refreshes.
- **Creation**: `CREATE MATERIALIZED VIEW materialized_view_name AS query`.
- **Usage Benefit**: When a user references a materialized view, they query pre-joined/pre-computed data.
- **Use Case**: Useful when some latency between refreshes is acceptable.

### Lab Overview

- Work with a star schema model using DBT.
- Create analytical views on top of the model.

# Course Capstone Project

## Summary of the Program Concepts

### Program Overview

- Covered the **data engineering life cycle**, technologies, and best practices for building data solutions in the **Cloud**.
- Hands-on practice with data engineering concepts in lab exercises.
- Focus: Preparing for the **Capstone labs**.

### Thinking Like a Data Engineer

- **Work backward**: Identify stakeholder needs and how they derive value from data.
- Translate needs into system requirements, choosing appropriate tools and technologies.
- Build and iterate on data systems with a focus on end-users and their data needs.

### Data Ingestion

- Ingestion depends on the source system (database, file, streaming system, API).
- **Batch ingestion**: Historical data from files or databases.
- **Streaming ingestion**: Real-time data from streaming systems.
- Ingestion approach guided by stakeholder needs and system requirements.
- Can serve as the extract phase in **ETL** or **ELT** processes.

### Data Transformation

- **ETL**: In-flight transformations before loading into the target system.
- **ELT**: Transformations applied after loading into the target system.
- Choice depends on transformations, hardware specs, and data size.
- Encompasses cleaning, combining data, and converting data into a target schema.
- Target schema depends on the data model (**star schema**, **one big table**).
- Transformation methods: **SQL queries**, **Python** code.
- Processing tools: **Pandas** (non-distributed), **Spark** (distributed).
- Cloud **data warehouse**: Leveraging massively parallel processing power.
- **DBT**: Facilitates data modeling inside a data warehouse.

### Data Warehouses vs. Data Lakes vs. Data Lakehouses

- **Data warehouses**: For analytical workloads, based on columnar storage; optimized for aggregating queries.
- **Data lakes**: Built on low-cost object storage, supporting machine learning and big data processing.
- **Data Lakehouse**: Combines data lake storage with data warehouse querying and management.
- Blurred lines: Data warehouses adapting lake-like features, data lakes incorporating warehouse-like capabilities.

### Data Engineering Undercurrents

- **IAM**: Ensuring security by preventing unauthorized access.
- **Networking (VPCs, route tables, ACLs, security groups)**: Securing resources.
- **Data Management**: Modeling data, using data catalogs, organizing data storage.
- **Data Quality**: Testing and monitoring with tools like **Great Expectations** and **Glue Data Quality**.
- **DataOps**: Automation using **Infrastructure as Code (Terraform)**; Orchestration using **Airflow**.

### Capstone Lab

- End-to-end data pipeline.
- Part 1: Creating and configuring pipeline resources.
- Part 2: Integrating data quality checks and orchestration.

## Lab Walkthrough - Capstone Project (Part 1)

### Project Overview

- Design an end-to-end data pipeline as a solution to a business use case.
- **Part 1**: Create and configure resources for the pipeline.
- **Part 2**: Integrate data quality checks, orchestration, and create data visualizations.

### Business Problem: De Ftunes Music Streaming Service

- **De Ftunes**: A subscription-based music streaming service.
- New feature: Clients can purchase and download music.
- **Data analytics team** wants to analyze the purchase data.
- **Requirements**: Track service performance, analyze purchase data by song, artist, time, and user location.

### Available Data Sources

- **API Endpoints**:
  - **Sessions**: Transactional session information (user ID, purchased songs, song/artist info, price, like status).
  - **Users**: User information (first/last names, location, time zone, subscription date).
- **PostgreSQL Database**: Contains song information (track ID, title, release album, artist information, year released) in the `Songs` table under the `De.Ftunes` schema.

### Data Modeling & Storage Requirements

- **Ingest**, **combine**, and **model** data for efficient querying by data analysts.
- Store **historical raw data**.
- Daily updates to the **model data**.
- Storage options: **Data lake bucket** and **Redshift cluster**.

### Data Modeling Approach: Star Schema

- **Fact Table**: Represents a single item purchased within a session.
  - **Fact Key** (surrogate key based on session ID and song ID).
  - Foreign Keys: `song_key`, `user_key`, `artist_key`, `session_start_time`.
  - Quantitative Measures: `price`, `liked`, `liked_since`.
- **Dimension Tables**: `user`, `time`, `song`, and `artist` to provide additional context.

### Data Pipeline Architecture

- Medallion Architecture: Bronze (Landing), Silver (Transformation), Gold (Serving)
- Extract raw data using **AWS Glue ETL jobs** defined in **Terraform**.
  - API Data (Users & Sessions): Store as JSON files in the landing zone.
  - Song Data (Postgres): Store as CSV file in the landing zone.
- Enrich raw datasets, add lineage metadata using Glue ETL jobs.
  - `transform_json_job`: Processes Users and Sessions JSON files, creating columns for location (latitude, longitude etc.), ingestion time and processing time. Stores as **Iceberg tables.**
  - `transform_songs_json_job`: Processes the CSV file into a dataframe. Schema enforcement, add ingested date and database name. Stores data in **Iceberg format**.
  - Create a **database catalog** called `transform_db`.
- Model the data using the **star schema** and store data in the **data warehouse** (serving zone) using **Redshift Spectrum**.
  - **Redshift Spectrum** allows querying processed data from the transformation zone of the data lake bucket without loading into the Redshift cluster

#### Terraform Configuration

- Define **Redshift provider** using credentials.
- Create schemas: `internal` (star schema data) and `external` (references the glue data catalog).
- Specify an **IAM role** allowing Redshift Spectrum to access the S3 bucket.

### Lab Tasks (Part 1)

- Use **Terraform** to create the data pipeline resources.
- Complete **Glue scripts** and **Terraform configuration files**.
- Set up the **DBT project folder**.
- Optionally define and create star schema tables using **DBT**.

### Next Steps (Part 2)

- Orchestrate the data pipeline using **Airflow**.
- Implement **data quality checks** in the transformation zone.
- Build **analytical views** on top of the star schema.
- Visualize the data as a data analyst.

# Week 4 Quiz

## Questions

1. Which of the following serving methods is best for serving large files of semi-structured or unstructured data?
   1. Object storage or data lakes
   2. Email
   3. CSV files
   4. OLAP databases
2. What is one advantage of using a data sharing platform?
   1. Ensures a coherent and consistent version for the shared files
   2. Supports real-time streaming data
   3. Supports high performance complex queries
3. Which of the following is a benefit of serving data directly from OLAP databases and data warehouses?
   1. Schema enforcement
   2. Supports real-time streaming data
   3. Supports sharing large files of unstructured data
   4. Supports easy file versioning
4. What’s the purpose of a semantic layer that sits on top of your data model?
   1. To represent a virtual table that provides easier access to common queries.
   2. To translate the underlying data elements and structures into business terms that help end users navigate the data.
   3. To reduce the time it takes to serve data to end users.
   4. To serve department-specific data needs.
5. How can you create a semantic layer that sits on top of your data model? Select all that apply.
   1. Using BI tools
   2. Use a software like dbt
   3. Use Amazon SageMaker
   4. Microsoft Azure Machine Learning
6. What is a key difference between a view and a materialized view?
   1. A view precomputes and stores query results, while a materialized view needs to be executed every time the view if refreshed.
   2. A view is useful when you need real-time data updates, while a materialized view does not support real-time data streaming.
   3. A materialized view can only be used within the scope of a single query, while a view can be used throughout all of your queries.
   4. A materialized view caches query results and allows periodic refreshes, while a materialized view needs to be executed every time the view if refreshed.
7. What is a key difference between a view and a common table expression (CTE)?
   1. A view performs precomputation, while a CTE does not.
   2. A CTE can be accessed by external database users, while a view cannot.
   3. A CTE is stored on the database disk, while a view is not.
   4. A view is a persistent database object, while a CTE is temporary and only exists within the scope of a single query.
8. What is one way a view can be used to enhance data security?
   1. By combining tables into a wide table
   2. By encrypting the data stored in the view
   3. By providing a virtual table and not a physical one.
   4. By selecting only specific columns and rows to restrict data access
9. When thinking like a data engineer, what is the first step you should take when starting a new data project?
   1. Ingest data from source systems
   2. Start building and iterating on your data system
   3. Identify the needs of your stakeholders
   4. Choose the appropriate tools and technologies

## Answers

1. 1
2. 1
3. 1
4. 2
5. 1 & 2
6. 4
7. 4
8. 4
9. 3

# Summary, Resources & Acknowledgements

- [Joe's thoughts on what's happening with Data Engineering](https://joereis.substack.com/p/data-engineering-in-2024-what-im)
- [Start data engineering posts](https://www.startdataengineering.com/post/)
- [Ideas for data engineering projects](https://www.theseattledataguy.com/7-data-engineering-projects-to-put-on-your-resume/#page-content)

## The Future of Data Engineering

### Evolving Roles in Data

- Boundaries between **software engineering**, **data engineering**, **data science**, and **machine learning** are blurring.
- Data is increasingly embedded in business processes, leading to new data and algorithm-related roles.
- Potential blending of **data and machine learning engineering**.
- **Machine learning** is transitioning to an operational discipline. Focus on systems that automatically train models, monitor performance, and operationalize machine learning processes.
- **Machine learning engineers** might specialize in model types closer to research.
- **Software engineers** need a deeper understanding of data engineering (streaming, data pipelines, modeling, quality).
- **Data engineers** will be integrated into application development teams.
- Lowered boundaries between application back-end systems and data engineering tools through **streaming** and **event-driven architectures**.

### Future of Data Engineering Tools and Technologies

- Shift towards **simplified, easy-to-use tools**.
- Increased **interoperability** across applications and systems.
- **Abstraction** allows engineers to focus on complex, value-added problems.
- **Streaming pipelines** and **real-time analytical databases** will become more accessible and pervasive. Easier deployment with managed **Cloud services.**
- **Batch transformations** will remain useful for model training, reporting, etc., but **streaming transformations** will gain prominence.

### AI Integration in Data Engineering

- Companies are seeking AI use cases, such as **GitHub Copilot**.
- **AI-enabled workflows** are unlikely to replace handwritten code entirely, as engineers want to "engineer." They primarily make work easier.

### Advice for Aspiring Data Engineers

- Work on personal **data engineering projects**.
- Engage with the data engineering **community** (meetups, questions, sharing expertise).
- Stay updated by reading books, blogs, and papers; listen to talks from domain experts.

### Final Thoughts

- Optional final lesson with interviews from industry experts (Jack Wilson, Carly Taylor, Ben Roggan) provides career advice in data.

## Interview with Zach Wilson: Data Engineering Insights

### Introduction

- Interview with **Zach Wilson**, a data engineer with 10 years of experience at **Facebook**, **Netflix**, and **Airbnb**.
- Zach is now an entrepreneur and teacher at **DataExpert.io**.

### Getting Your First Data Engineering Job

- **Finding Junior Roles**: Difficult due to companies wanting experienced data engineers to manage pipelines.
- **Adjacent Roles**: Start as a **Software Engineer** or **Data Analyst** to build foundational skills.
- **Skills Overlap**: 70% overlap between the skills required for backend, data, and other roles.

### Key Skills for Data Engineers

- **Essential Tooling:**
  - Fundamental Linux skills (bash scripting).
  - Experience with Cloud Services (e.g., **BigQuery**, **Airflow**, **Spark**).
  - Proficiency in Coding Languages (**Python**, **Bash**, **SQL**).
- **Pipeline Building**: Understanding how to stitch services together to build data pipelines.

### Becoming a Good Data Engineer

- **Beyond Pipeline Implementation**: Thinking about the _why_ and the _impact_ of the pipeline.
- **Knowing When to Say No**: Resisting the urge to build pipelines for every request.
- **Avoiding Burnout**: Prioritizing repeatable tasks and setting boundaries.

### Advice to Younger Self

- **Self-Marketing**: Work does _not_ speak for itself; actively promote your work.
- **Feedback**: Solicit feedback to improve your work.
- **Learn Spark Sooner**: Recognize the importance of new technologies early and invest in learning them.

### Staying Up-to-Date

- **Pushing Boundaries**: Focus on the three V's (**Volume**, **Velocity**, **Variety**).
- **Adjacent Opportunities**: Seek out teams and projects that align with your goals.
- **Growth Mindset**: Recognize when you're not growing in a role and seek out supportive environments.
- **Manager Communication**: Seek growth opportunites yourself and explain the value to your manager,

### Determining Value in Work

- **Early Career (Junior to Senior)**: Prioritize measurable impact (e.g., data model efficiency, business metric lifts).
- **Later Career (Beyond Senior)**: Focus on leveraged or horizontal impact (e.g., changing _how_ work is done).

#### Example of Leveraged Impact

- Improving Spark pipeline deployment time by identifying and removing unnecessary code.
- Encouraging the team and company to adopt the improvement.

### Future of Data Engineering

- **Smarter Service Owners**: Service owners taking greater responsibilty for logging and data generation
- **Morphing Roles**: Backend engineers and data engineers merging as service owners handle their own data.
- **Analytics Engineer Expansion**: This role with be more important for cleaning and metrics generations. Data engineers with expertise in analytics.
- **Unstructured Data Focus**: New techniques needed to handle and validate unstructured data from LLMs. The concept of rows and columns disapearing and being replaced by a bunch of unstructured data.

### AI Impact and Hybrid Roles

- Will impact data engineering (a large question mark)
- Hybrid roles with software and data fusion may become more common in larger companies.
- Companies using **JVM** backends could experience this _hybrid_ role more easily.
- **DataExpert**: Zach Wilson's company focusing on teaching.
- **Contact Info**: @EcZachly on social media.

## Career Advice for Data Professionals with Carly Taylor

### Introduction

- Interview with Carly Taylor, who works on **machine learning at Call of Duty** and is a content creator.
- Aim: To provide **career advice** to those in or aspiring to be in the data field.

### Carly's Journey into Data

- Background in **chemistry**.
- Entered data via a **marketing analyst** role.
- **Key takeaway**: Quantitative skills can be leveraged even without domain expertise.
- Stressed the importance of **on-the-job training**, but also recommends taking **business classes** to learn the jargon.

### A Day in the Life of a Machine Learning Engineer (at Activision)

- Starts with **stand-up meetings**.
- **70% Exploratory Data Analysis (EDA)**: Understanding the data.
- **20% Modeling**.
- **10% Production and monitoring**.
- Engineers are expected to have some data engineering chops.

### Data Engineer vs. Machine Learning Engineer

- **Data Engineer**: Focus on data quality and pipeline integrity. Expectation to ensure factual data and no data loss. Less focus on business context.
- **Machine Learning Engineer**: Focus on understanding data in a **business context** and building predictive models on top of it. Sanity checks data.
- Carly described it as **Availability** (DE) vs **Understanding** (MLE).

### Machine Learning Applications at Call of Duty

- **Computer Vision**.
- **Anomaly detection** (security-focused, like fraud analysis).
- Detecting outliers in data.

### Transitioning from Individual Contributor to Leadership

- The transition came out of **necessity** when there was a lack of leadership.
- Stepping up when something is lacking is when you grow.

### Advice to Younger Self

- Give yourself grace to not know everything.
- Avoid burnout by not trying to keep up with everything in data science.
- Pick a specialty sooner.
- Strive for **T-shaped knowledge**: Depth in a specific area of expertise and breadth in other areas.

#### T-Shaped Knowledge Explained

- A T-shape knowledge has a wide breadth of knowing a lot about different things, but also has a smaller section in the T-shape that has depth in a specific area of expertise.
- Expertise might look more like a T-shape and it'll be centered around that area that you find is your area of expertise.
- Not everyone has to know everything about everything.

### Advice for Getting the First Job in Data

- Have your **resume reviewed** by multiple people.
- Be willing to **change** your resume if it's not working.
- Don't be precious about past accomplishments if they aren't relevant.

### Standing Out in a Competitive Job Market

- Leverage the trend of **video submissions**.
- Put in the effort to create **high-quality videos**: Good lighting, polished appearance, thoughtful answers.
- Being just slightly better (5%) than the average applicant can make you stand out.

### Final Advice

- Taking courses is a good sign that it sets you on a path for success.
- Be kind to yourself and give yourself grace to not always perform at 100%,
- Keep in mind that it is hard to convince yourself and others that they should take a risk on you.
- Keep showing up.

## Interview with Ben Rogojan (Seattle Data Guy)

### Introduction

- Interview with **Ben Rogojan**, also known as **Seattle Data Guy**.
- Ben has worked in the data world for almost a decade.
- Started with aspirations in **data science** but transitioned to **data engineering**.

### Ben's Journey

- Discovered data engineering by searching for jobs using skills like **SQL**, **Python**, **automation**, and **data warehousing**.
- First data engineering role was at a healthcare analytics startup.
- Later worked at **Facebook** and now does consulting in data engineering and data infrastructure.
- Acknowledges the challenges of keeping up with the rapid changes in data engineering.

### Early Days as a Data Engineer

- At the startup, he worked with healthcare claims data from various insurance providers.
- Data standardization was a major task due to differing data formats.
- Experienced various data separation methods, including position-delimited fields.
- Built products for fraud detection and opioid tracking.
- Initial tech stack involved **PowerShell** and **SQL Server**.

### Experience at Facebook

- Acknowledges that Facebook has a mature data infrastructure, so some find it boring.
- Focus shifted from coding ability to **communication** and **finding problems worth solving**.
- Spent time understanding team needs and identifying recurring problems.
- The goal was to **eliminate repeated tasks** and improve infrastructure.
- Facebook's internal tools like **Presto** and **Hive** emerged from this problem-solving.

### Importance of Communication and Problem-Solving

- Data engineers need to differentiate themselves by identifying and solving impactful problems.
- Communication with teams is crucial to understand their daily challenges.
- Getting rid of 1000 tasks is better than solving 1000 individual tasks.

### Advice for Aspiring Data Engineers

- Start with the **technical fundamentals**: **SQL**, **Python**, **data warehousing**, and data pipelines.
- Understand **why data pipelines are built** and their purpose.
- Solidify skills and then question their impact on the business.
- Book recommendation: Joe Reese's book for understanding data engineering concepts.
- Industry spends billions on **EL (Extract, Load)** alone. Ask: Why are we doing this?

### On Learning About Business

- Start by working at a company to gain practical experience.
- Early in the career, focus on improving engineering skills while asking inquisitive questions about the business.
- As technical confidence grows, shift focus towards the business aspects.
- Talk to non-technical people to understand their perspectives.
- Focus on the business value of real-time data instead of just technological advancement.

### Real-Time Data Expectations

- Need to define clearly what "real-time" means in a specific context.
- The definition can vary significantly, from 12-24 hours to even monthly updates.
- Asking good questions about requirements is essential.

### Excitement and Hopes for the Future

- Hope to shift towards building reliable and usable datasets over the long term.
- There is a need for proper implementation, even with multi-stack/multi-engine data infrastructure architectures.
- Revisit fundamentals and implement them well, especially with the rise of AI.
- Address data management and data quality to improve AI outcomes.

### Finding Ben Rogojan

- YouTube or Substack: **Seattle Data Guy**.
- Also find him on LinkedIn.
